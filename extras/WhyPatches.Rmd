---
title: "Why To Use Patches"
author: "John Mount"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
---

# Why To Use Patches

#### Introduction

One of the big selling points of the [`R`](https://cran.r-project.org) package [`dplyr`]( https://CRAN.R-project.org/package=dplyr) is it lets you use the a grammar of data manipulation to work with data from a variety of data sources:

 * local `data.frame`s.
 * Databases (`SQLite`, `PostgreSQL`, `MySQL`, and more).
 * [`Spark`](http://spark.apache.org) (via [`SparklyR`](https://CRAN.R-project.org/package=sparklyr)).
 
This yields the *expectation* that the same code will have similar results on these multiple data sources.  This in fact not quite the case.  One has the weaker circumstance that while some `dplyr` code will often work with each of these data sources.

That is one may have to adapt or patch a `dplyr` workflows to the particular data source you are working with.  The [`replyr` package]( https://CRAN.R-project.org/package=replyr) includes a collection of patches that attempt to make it possible to write code that will run correctly on a variety of data sources.  Our current emphasis is running correctly on [`RPostgreSQL`]( https://CRAN.R-project.org/package=RPostgreSQL) and [`Sparklyr`]( https://CRAN.R-project.org/package=sparklyr) as this adds significant medium data and big data capabilities to [`R`](https://cran.r-project.org). 

#### Example

The above is much clearer if we work a concrete example.

Let's first start up an `R` instance.

```{r setup}
base::date()
suppressPackageStartupMessages(library("dplyr"))
packageVersion("dplyr")
packageVersion("dbplyr")
suppressPackageStartupMessages(packageVersion("sparklyr"))
packageVersion("sparklyr")
library("replyr")
packageVersion("replyr")
R.Version()$version.string
```

We will start with a local `data.frame` example.  We create a `data.frame`, use a function to add a column, and perform a couple of example joins.

One must understand that these operations are not meant to look meaningful on their own.  They are the types of code one sees in the middle of larger meaningful data transformations.  The sub-operations we are calling out include:

 * Creating a table.
 * Adding a constant character column to the table (our example functions `f()` and `fCast()`).
 * Performing a simple join (our example function `fJoin()`).

We are going to spare the reader any "motivating story" or cutesy pretend application. In return we ask the reader trust us that non-trivial data 
projects include many steps at least this complicated, and at least this 
abstract.

Let's set up our data and define our functions.

```{r dataandfunction}
dLocal <- data.frame(x = 1:2,
                     origCol = c('a', 'b'),
                     stringsAsFactors = FALSE)

f <- function(dt) {
  mutate(dt, newCol= 'a')
}

fCast <- function(dt) {
  mutate(dt, newCol= as.character('a'))
}

fJoin <- function(d1, d2) {
  inner_join(d1, d2,
           by=c('origCol'='newCol'))
}
```

And let's show a typical use of them on a "local" `data.frame`.

```{r localexample}
d <- dLocal

# call our function on table
dR <- f(d)
print(dR)

# work with result
fJoin(dR, dR)

# cast function works very similar
dRC <- fCast(d)
print(dRC)

# again, can work with the result
fJoin(dRC, dRC)

# clean up
rm(list= c('d', 'dR', 'dRC'))
```

That is our example project, and it worked just fine on in-memory or local data.

#### `SQLite` example

We can show some of the versatility of `dplyr` by trying the exact same code
on an (in-memory) `SQLite` database.

```{r SQLiteexample}
# set up db connection and copy data over
sc <- dplyr::src_sqlite(":memory:", 
                        create = TRUE)
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- f(d)
print(dR)

# work with result
fJoin(dR, dR)

# cast function works very similar
dRC <- fCast(d)
print(dRC)

# again, can work with the result
fJoin(dRC, dRC)
```

Notice the exact same code worked on the data even when it is in a database.  This is a big advantage.  Experience earned using `dplyr` on `data.frame`s can be re-used when working with databases.  Procedures can be rehearsed, and code can be re-used.  `dplyr` isn't promising us a single "better in-memory `data.frame`" is is giving us the ability to delegate implementation to other systems including substantial databases and `Spark`.

```{r SQLiteCleanup, include=FALSE}
# clean up
rm(list= c('d', 'dR', 'dRC')); gc(verbose = FALSE)
```


#### PostgreSQL example

We can try this exact same workflow on a `PostgreSQL` database. 


```{r PostgreSQLexample}
sc <- dplyr::src_postgres(host = 'localhost',
                          port = 5432,
                          user = 'postgres',
                          password = 'pg')
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- f(d)
print(dR)
```

We got a warning, that should make us worried.  And indeed the `dR` table is "not quite right" and triggers an error in our simple join.

```{r PGEe, error=TRUE}
# work with result
fJoin(dR, dR)
```

This error is in fact why we have the function `fCast()`.  The cast version of `f()` seems to inform `PostgreSQL` of the needed type information and allow a correct join.

```{r PGC}
# cast function version
dRC <- fCast(d)
print(dRC)

# again, can work with the result
fJoin(dRC, dRC)
```

At this point it appears that just adding an extra cast will give us code that works everywhere. Of course one has to remember to do this. To make remembering simple we have a function called `replyr::addConstantColumn()` which attempt to remember if the cast is needed (which depends both on the type of the value being added and the database we are working with). This is a small thing, but once you have a lot of these they can be substantial.

```{r PostgreSQLCleanup, include=FALSE}
# clean up
dplyr::db_drop_table(sc$con, 'd')
rm(list=c('sc', 'd')); gc(verbose = FALSE)
```


#### `Spark`

`Spark` is becoming a very important system for `R` users due to its ability to work at scale and be scripted through the `SparkR` or `SparklyR` interfaces.

Notice in this `Spark 2.0.2` example we can use the same code as the original example (we are only using `replyr::addConstantColumn()` as a choice).

```{r Sparkexample}
sc <- sparklyr::spark_connect(version= '2.0.2', 
                              master= "local")
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')

# work with result
fJoin(dR, dR)
```

```{r SparkCleanup, include=FALSE}
# clean up
sparklyr::spark_disconnect(sc)
```


### Conclusion

At this point we have shown that while `dplyr` can work over multiple data sources, it often needs somewhat different code for each one.  This makes writing reliable, re-usable, *generic* code needlessly difficult.  Each of these problems is easy to fix if they the entirety of your goals, but as interruptions in laying out a larger workflow they can be killing distractions.  [`replyr`]( https://CRAN.R-project.org/package=replyr) is (among other things) a patch-set in convenient package form.

We suggest using a genericising adapter such as `replyr` to work around these differences in production.  

We do, as a public service, file everything we find as concise issues with the original projects; but one needs to make progress on actual production work in the meantime (and often the issues do not appear to be considered a high priority).


## Appendix: other currently needed work-arounds or patches

The following are all small speed bumps that are easy to move past, *if* they were what you were directly working and thinking about.  Hidden as steps in larger code or packages they can produce wrong results or at least trigger long debugging sessions.

### nrow

From [`dplyr` issue 2871](https://github.com/tidyverse/dplyr/issues/2871):

```{r rnrow}
d <- data.frame(x = 1:3)

# expected behavior
nrow(d)
#> [1] 3

# db vector behavior (throws)
dS <- dbplyr::memdb_frame(x = 1:3)
print(dS)

# return NA
nrow(dS)

# works
replyr_nrow(dS)
```


### union_all

```{r unionall, error=TRUE}
my_db <- dplyr::src_sqlite(":memory:", create = TRUE)
dr <- dplyr::copy_to(my_db,
                     data.frame(x= c(1,2),
                                y= c('a','b'),
                                stringsAsFactors = FALSE),
                     'dr',
                     overwrite=TRUE)
dr <- head(dr,1)

# works
replyr_union_all(dr, dr)

# throws
dplyr::union_all(dr, dr)
```

### rename

From [`dplyr` issue 2860](https://github.com/tidyverse/dplyr/issues/2860):

```{r rename, error=TRUE}
df <- dbplyr::memdb_frame(x = 1:3, y = 4:6)
df

# works
df %>% replyr_mapRestrictCols(c('A'='x', 'B'='y'))

# throws
df %>% rename(A=x, B=y)
```



## Appendix: re-run initial examples with `replyr::addConstantColumn()`

In this appendix we re-run the initial examples with `replyr::addConstantColumn()` to confirm our claim `replyr::addConstantColumn()` works in a generic sense.

```{r localexampleRedo}
d <- dLocal

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')
print(dR)

# work with result
fJoin(dR, dR)
```

```{r SQLiteexampleRedo}
# set up db connection and copy data over
sc <- dplyr::src_sqlite(":memory:", 
                        create = TRUE)
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')
print(dR)

# work with result
fJoin(dR, dR)
```

```{r PostgreSQLexampleRedo}
sc <- dplyr::src_postgres(host = 'localhost',
                          port = 5432,
                          user = 'postgres',
                          password = 'pg')
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')
print(dR)

# work with result
fJoin(dR, dR)
```

