---
title: "Why To Use Patches"
author: "John Mount"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
---

# Why To Use Patches

#### Introduction

One of the big selling points of the [`R`](https://cran.r-project.org) package [`dplyr`]( https://CRAN.R-project.org/package=dplyr) is it lets you use the a grammar of data manipulation to work with data from a variety of data sources:

 * local `data.frame`s.
 * Databases (`SQLite`, `PostgreSQL`, `MySQL`, and more).
 * [`Spark`](http://spark.apache.org) (via [`SparklyR`](https://CRAN.R-project.org/package=sparklyr)).
 
This yields the *expectation* that the same code will have similar results on these multiple data sources.  This in fact not quite the case.  One has the weaker circumstance that while some `dplyr` code will often work with each of these data sources.

That is one may have to adapt or patch a `dplyr` workflows to the particular data source you are working with.  The [`replyr` package]( https://CRAN.R-project.org/package=replyr) includes a collection of patches that attempt to make it possible to write code that will run correctly on a variety of data sources.  Our current emphasis is running correctly on [`RPostgreSQL`]( https://CRAN.R-project.org/package=RPostgreSQL) and [`Sparklyr`]( https://CRAN.R-project.org/package=sparklyr) as this adds significant medium data and big data capabilities to [`R`](https://cran.r-project.org). 

#### Example

The above is much clearer if we work a concrete example.

Let's first start up an `R` instance.

```{r setup}
base::date()
suppressPackageStartupMessages(library("dplyr"))
packageVersion("dplyr")
packageVersion("dbplyr")
suppressPackageStartupMessages(packageVersion("sparklyr"))
packageVersion("sparklyr")
library("replyr")
packageVersion("replyr")
R.Version()$version.string
```

We will start with a local `data.frame` example.  We create a `data.frame`, use a function to add a column, and perform a couple of example joins.

One must understand that these operations are not meant to look meaningful on their own.  They are the types of code one sees in the middle of larger meaningful data transformations.  The sub-operations we are calling out include:

 * Creating a table.
 * Adding a constant character column to the table (our example functions `f()` and `fCast()`).
 * Performing a simple join (our example function `fJoin()`).

We are going to spare the reader any "motivating story" or cutesy pretend application. In return we ask the reader trust us that non-trivial data 
projects include many steps at least this complicated, and at least this 
abstract.

Let's set up our data and define our functions.

```{r dataandfunction}
dLocal <- data.frame(x = 1:2,
                     origCol = c('a', 'b'),
                     stringsAsFactors = FALSE)

f <- function(dt) {
  mutate(dt, newCol= 'a')
}

fCast <- function(dt) {
  mutate(dt, newCol= as.character('a'))
}

fJoin <- function(d1, d2) {
  inner_join(d1, d2,
           by=c('origCol'='newCol'))
}
```

And let's show a typical use of them on a "local" `data.frame`.

```{r localexample}
d <- dLocal

# call our function on table
dR <- f(d)
print(dR)

# work with result
fJoin(dR, dR)

# cast function works very similar
dRC <- fCast(d)
print(dRC)

# again, can work with the result
fJoin(dRC, dRC)

# clean up
rm(list= c('d', 'dR', 'dRC'))
```

That is our example project, and it worked just fine on in-memory or local data.

#### `SQLite` example

We can show some of the versatility of `dplyr` by trying the exact same code
on an (in-memory) `SQLite` database.

```{r SQLiteexample}
# set up db connection and copy data over
sc <- dplyr::src_sqlite(":memory:", 
                        create = TRUE)
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- f(d)
print(dR)

# work with result
fJoin(dR, dR)

# cast function works very similar
dRC <- fCast(d)
print(dRC)

# again, can work with the result
fJoin(dRC, dRC)
```

Notice the exact same code worked on the data even when it is in a database.  This is a big advantage.  Experience earned using `dplyr` on `data.frame`s can be re-used when working with databases.  Procedures can be rehearsed, and code can be re-used.  `dplyr` isn't just promising us a single "better in-memory `data.frame`" it is giving us the ability to delegate implementation to other systems including substantial databases and `Spark`.

```{r SQLiteCleanup, include=FALSE}
# clean up
rm(list= c('d', 'dR', 'dRC')); gc(verbose = FALSE)
```


#### PostgreSQL example

We can try this exact same workflow on a `PostgreSQL` database. 


```{r PostgreSQLexample}
sc <- dplyr::src_postgres(host = 'localhost',
                          port = 5432,
                          user = 'postgres',
                          password = 'pg')
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- f(d)
print(dR)
```

We got a warning, that should make us worried.  And indeed the `dR` table is "not quite right" and triggers an error in our simple join.

```{r PGEe, error=TRUE}
# work with result
fJoin(dR, dR)
```

This error is in fact why we have the function `fCast()`.  The cast version of `f()` seems to inform `PostgreSQL` of the needed type information and allow a correct join.

```{r PGC}
# cast function version
dRC <- fCast(d)
print(dRC)

# again, can work with the result
fJoin(dRC, dRC)
```

At this point it appears that just adding an extra cast will give us code that works everywhere. Of course one has to remember to do this. To make remembering simple we have a function called `replyr::addConstantColumn()` which attempt to remember if the cast is needed (which depends both on the type of the value being added and the database we are working with). This is a small thing, but once you have a lot of these they can be substantial.

```{r PostgreSQLCleanup, include=FALSE}
# clean up
dplyr::db_drop_table(sc$con, 'd')
rm(list=c('sc', 'd')); gc(verbose = FALSE)
```


#### `Spark`

`Spark` is becoming a very important system for `R` users due to its ability to work at scale and be scripted through the `SparkR` or `SparklyR` interfaces.

Notice in this `Spark 2.0.2` example we can use the same code as the original example (we are only using `replyr::addConstantColumn()` as a choice).

```{r Sparkexample}
sc <- sparklyr::spark_connect(version= '2.0.2', 
                              master= "local")
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')

# work with result
fJoin(dR, dR)
```

```{r SparkCleanup, include=FALSE}
# clean up
sparklyr::spark_disconnect(sc)
```


### Conclusion

At this point we have shown that while `dplyr` can work over multiple data sources, it often needs somewhat different code for each one.  This makes writing reliable, re-usable, *generic* code needlessly difficult.  Each of these problems is easy to fix if they the entirety of your goals, but as interruptions in laying out a larger workflow they can be killing distractions.  [`replyr`]( https://CRAN.R-project.org/package=replyr) is (among other things) a patch-set in convenient package form.

We suggest using a genericising adapter such as `replyr` to work around these differences in production.  

We do, as a public service, file everything we find as concise issues with the original projects; but one needs to make progress on actual production work in the meantime.


## Appendix: other currently needed work-arounds or patches

The following are all small speed bumps that are easy to move past, *if* they were what you were directly working and thinking about.  Hidden as steps in larger code or packages they can produce wrong results or at least trigger long debugging sessions.

### nrow / counting rows

From [`dplyr` issue 2871](https://github.com/tidyverse/dplyr/issues/2871):

```{r rnrow}
d <- data.frame(x = 1:3)

# expected behavior
nrow(d)
#> [1] 3

# db vector behavior (throws)
dS <- dbplyr::memdb_frame(x = 1:3)
print(dS)

# return NA
nrow(dS)

# works
replyr_nrow(dS)
```


### union_all

```{r unionall, error=TRUE}
my_db <- dplyr::src_sqlite(":memory:", create = TRUE)
dr <- dplyr::copy_to(my_db,
                     data.frame(x= c(1,2),
                                y= c('a','b'),
                                stringsAsFactors = FALSE),
                     'dr',
                     overwrite=TRUE)
dr <- head(dr,1)

# works
replyr_union_all(dr, dr)

# throws
dplyr::union_all(dr, dr)
```

### rename

From [`dplyr` issue 2860](https://github.com/tidyverse/dplyr/issues/2860):

```{r rename, error=TRUE}
df <- dbplyr::memdb_frame(x = 1:3, y = 4:6)
df

# works
df %>% replyr_mapRestrictCols(c('A'='x', 'B'='y'))

# throws
df %>% rename(A=x, B=y)
```

### counting rows again

From [`dplyr` issue 2080](https://github.com/tidyverse/dplyr/issues/2080]):

```{r counting}
suppressPackageStartupMessages(library(dplyr))
library(purrr)

df <- tibble(x = list(
  tibble(y = 1:2),
  tibble(y = 1:3),
  tibble(y = 1:4)
))

nrows <- function(df) {
  df %>% summarise(n = n()) %>% .[["n"]]
}

df %>%
  mutate(
    n1 = x %>% map_int(nrows),
    n2 = x %>% map_int(. %>% summarise(n = n()) %>% .[["n"]]),
    n3 = map_int(x, ~ summarise(., n = n())[["n"]]),
    n4 = map_int(x, function(df) summarise(df, n = n())[["n"]]),
    n5 = x %>% map_dbl(replyr::replyr_nrow)
  )
```

All of these functions are "the same", but only the ones that are externally wrapped (`nrows()` and `replyr_nrow()`) seem to have a sucessful execution environment (gets the nested row-counts right).  This example is a bit different than the others, it is a reason to prefer "pedestrian code [base-R](http://www.win-vector.com/blog/tag/base-r/)" (wrapping your own function) to some of the slick meta-notations.

Roughly: each of thes `tidyverse` packages `magrittr`, `dplyr`, and `purrr` has already consumed so much referential transparency that they don't work together without [further explicit coordination](https://github.com/tidyverse/magrittr/issues/141) (which consumes even more referential transparency, making working with additional systems and constraints even harder).



## Appendix: reasons to patch instead of waiting for a fix

An alternative to working around issues is to wait for `dplyr` itself to incorporate fixes, or at least work-arounds.  However this can take time, and there are indications that the `dplyr` authors do not see `dplyr` itself as the correct place to correct work-arounds.  We can try to guess intent by looking at package author comments from some of the issue reports:

 * ["Looks like its a bug in MySQL"](https://github.com/tidyverse/dplyr/issues/2777).
 * ["There's nothing we can do here - SQLite doesn't support this SQL."](https://github.com/tidyverse/dplyr/issues/2858) (To be clear: this is in reference to `SQL` generate by `dplyr`, not `SQL` passed in from user code.)
 * ["I don't see any obvious way to do better."](https://github.com/tidyverse/dplyr/issues/2830)
 
My guess is the `dplyr` development strategy is to emit a fairly consistent dialect of `SQL` to all `db`-backends.  This strategy is efficient, but may not work in all cases (["It's called SQL 92 because there's 92 versions of it...."](https://github.com/tidyverse/dplyr/issues/2800)). 

The user code may issue unintentionally difficult commands (as one of the points of the `dplyr` grammar is to spare the user the full details of `SQL`), but the user does expect and need them to be carried out.  It is a bit like the [programmer's credo](https://twitter.com/pinboard/status/761656824202276864?lang=en) (a parody of [JFK's Moon Speech](https://er.jsc.nasa.gov/seh/ricetalk.htm)):

> we do these things not because they are easy, but because we thought they were going to be easy

So `replyr` ends up collecting work-arounds and patches to avoid triggering situations that `dplyr` is not currently working around (right or wrong).


## Appendix: re-run initial examples with `replyr::addConstantColumn()`

In this appendix we re-run the initial examples with `replyr::addConstantColumn()` to confirm our claim `replyr::addConstantColumn()` works in a generic sense.

```{r localexampleRedo}
d <- dLocal

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')
print(dR)

# work with result
fJoin(dR, dR)
```

```{r SQLiteexampleRedo}
# set up db connection and copy data over
sc <- dplyr::src_sqlite(":memory:", 
                        create = TRUE)
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')
print(dR)

# work with result
fJoin(dR, dR)
```

```{r PostgreSQLexampleRedo}
sc <- dplyr::src_postgres(host = 'localhost',
                          port = 5432,
                          user = 'postgres',
                          password = 'pg')
d <- copy_to(sc, dLocal, 'd')

# call our function on table
dR <- replyr::addConstantColumn(d, 'newCol', 'a')
print(dR)

# work with result
fJoin(dR, dR)
```

